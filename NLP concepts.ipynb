{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4893fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph =\"Machine learning (ML) is a field of inquiry devoted to understanding and building methods that 'learn', that is, methods that leverage data to improve performance on some set of tasks.[1] It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so.[2] Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, agriculture, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.[3][4] A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers, but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.[6][7] Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.[8][9] In its application across business problems, machine learning is also referred to as predictive analytics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0a808da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a98d8e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f82f031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine',\n",
       " 'learning',\n",
       " '(',\n",
       " 'ML',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'inquiry',\n",
       " 'devoted',\n",
       " 'to',\n",
       " 'understanding',\n",
       " 'and',\n",
       " 'building',\n",
       " 'methods',\n",
       " 'that',\n",
       " \"'learn\",\n",
       " \"'\",\n",
       " ',',\n",
       " 'that',\n",
       " 'is',\n",
       " ',',\n",
       " 'methods',\n",
       " 'that',\n",
       " 'leverage',\n",
       " 'data',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'performance',\n",
       " 'on',\n",
       " 'some',\n",
       " 'set',\n",
       " 'of',\n",
       " 'tasks',\n",
       " '.',\n",
       " '[',\n",
       " '1',\n",
       " ']',\n",
       " 'It',\n",
       " 'is',\n",
       " 'seen',\n",
       " 'as',\n",
       " 'a',\n",
       " 'part',\n",
       " 'of',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " '.',\n",
       " 'Machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'build',\n",
       " 'a',\n",
       " 'model',\n",
       " 'based',\n",
       " 'on',\n",
       " 'sample',\n",
       " 'data',\n",
       " ',',\n",
       " 'known',\n",
       " 'as',\n",
       " 'training',\n",
       " 'data',\n",
       " ',',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'make',\n",
       " 'predictions',\n",
       " 'or',\n",
       " 'decisions',\n",
       " 'without',\n",
       " 'being',\n",
       " 'explicitly',\n",
       " 'programmed',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " '.',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'Machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " 'are',\n",
       " 'used',\n",
       " 'in',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'applications',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'in',\n",
       " 'medicine',\n",
       " ',',\n",
       " 'email',\n",
       " 'filtering',\n",
       " ',',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " ',',\n",
       " 'agriculture',\n",
       " ',',\n",
       " 'and',\n",
       " 'computer',\n",
       " 'vision',\n",
       " ',',\n",
       " 'where',\n",
       " 'it',\n",
       " 'is',\n",
       " 'difficult',\n",
       " 'or',\n",
       " 'unfeasible',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'conventional',\n",
       " 'algorithms',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'the',\n",
       " 'needed',\n",
       " 'tasks',\n",
       " '.',\n",
       " '[',\n",
       " '3',\n",
       " ']',\n",
       " '[',\n",
       " '4',\n",
       " ']',\n",
       " 'A',\n",
       " 'subset',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'closely',\n",
       " 'related',\n",
       " 'to',\n",
       " 'computational',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'which',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'making',\n",
       " 'predictions',\n",
       " 'using',\n",
       " 'computers',\n",
       " ',',\n",
       " 'but',\n",
       " 'not',\n",
       " 'all',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'statistical',\n",
       " 'learning',\n",
       " '.',\n",
       " 'The',\n",
       " 'study',\n",
       " 'of',\n",
       " 'mathematical',\n",
       " 'optimization',\n",
       " 'delivers',\n",
       " 'methods',\n",
       " ',',\n",
       " 'theory',\n",
       " 'and',\n",
       " 'application',\n",
       " 'domains',\n",
       " 'to',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '.',\n",
       " 'Data',\n",
       " 'mining',\n",
       " 'is',\n",
       " 'a',\n",
       " 'related',\n",
       " 'field',\n",
       " 'of',\n",
       " 'study',\n",
       " ',',\n",
       " 'focusing',\n",
       " 'on',\n",
       " 'exploratory',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'through',\n",
       " 'unsupervised',\n",
       " 'learning',\n",
       " '.',\n",
       " '[',\n",
       " '6',\n",
       " ']',\n",
       " '[',\n",
       " '7',\n",
       " ']',\n",
       " 'Some',\n",
       " 'implementations',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'use',\n",
       " 'data',\n",
       " 'and',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'that',\n",
       " 'mimics',\n",
       " 'the',\n",
       " 'working',\n",
       " 'of',\n",
       " 'a',\n",
       " 'biological',\n",
       " 'brain',\n",
       " '.',\n",
       " '[',\n",
       " '8',\n",
       " ']',\n",
       " '[',\n",
       " '9',\n",
       " ']',\n",
       " 'In',\n",
       " 'its',\n",
       " 'application',\n",
       " 'across',\n",
       " 'business',\n",
       " 'problems',\n",
       " ',',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'also',\n",
       " 'referred',\n",
       " 'to',\n",
       " 'as',\n",
       " 'predictive',\n",
       " 'analytics',\n",
       " '.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd1f81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3f118a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "701a3964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb6581e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "316d7a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organ'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('organization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bec9e370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee5439fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fe6c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer =WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "995900f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eating'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca0d8dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machin', 'learn', '(', 'ml', ')', 'is', 'a', 'field', 'of', 'inquiri', 'devot', 'to', 'understand', 'and', 'build', 'method', 'that', \"'learn\", \"'\", ',', 'that', 'is', ',', 'method', 'that', 'leverag', 'data', 'to', 'improv', 'perform', 'on', 'some', 'set', 'of', 'task', '.']\n",
      "['[', '1', ']', 'it', 'is', 'seen', 'as', 'a', 'part', 'of', 'artifici', 'intellig', '.']\n",
      "['machin', 'learn', 'algorithm', 'build', 'a', 'model', 'base', 'on', 'sampl', 'data', ',', 'known', 'as', 'train', 'data', ',', 'in', 'order', 'to', 'make', 'predict', 'or', 'decis', 'without', 'be', 'explicitli', 'program', 'to', 'do', 'so', '.']\n",
      "['[', '2', ']', 'machin', 'learn', 'algorithm', 'are', 'use', 'in', 'a', 'wide', 'varieti', 'of', 'applic', ',', 'such', 'as', 'in', 'medicin', ',', 'email', 'filter', ',', 'speech', 'recognit', ',', 'agricultur', ',', 'and', 'comput', 'vision', ',', 'where', 'it', 'is', 'difficult', 'or', 'unfeas', 'to', 'develop', 'convent', 'algorithm', 'to', 'perform', 'the', 'need', 'task', '.']\n",
      "['[', '3', ']', '[', '4', ']', 'a', 'subset', 'of', 'machin', 'learn', 'is', 'close', 'relat', 'to', 'comput', 'statist', ',', 'which', 'focus', 'on', 'make', 'predict', 'use', 'comput', ',', 'but', 'not', 'all', 'machin', 'learn', 'is', 'statist', 'learn', '.']\n",
      "['the', 'studi', 'of', 'mathemat', 'optim', 'deliv', 'method', ',', 'theori', 'and', 'applic', 'domain', 'to', 'the', 'field', 'of', 'machin', 'learn', '.']\n",
      "['data', 'mine', 'is', 'a', 'relat', 'field', 'of', 'studi', ',', 'focus', 'on', 'exploratori', 'data', 'analysi', 'through', 'unsupervis', 'learn', '.']\n",
      "['[', '6', ']', '[', '7', ']', 'some', 'implement', 'of', 'machin', 'learn', 'use', 'data', 'and', 'neural', 'network', 'in', 'a', 'way', 'that', 'mimic', 'the', 'work', 'of', 'a', 'biolog', 'brain', '.']\n",
      "['[', '8', ']', '[', '9', ']', 'in', 'it', 'applic', 'across', 'busi', 'problem', ',', 'machin', 'learn', 'is', 'also', 'refer', 'to', 'as', 'predict', 'analyt', '.']\n"
     ]
    }
   ],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    print(words)\n",
    "    corpus.append(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db5f01fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"machin learn ( ml ) is a field of inquiri devot to understand and build method that 'learn ' , that is , method that leverag data to improv perform on some set of task .\",\n",
       " '[ 1 ] it is seen as a part of artifici intellig .',\n",
       " 'machin learn algorithm build a model base on sampl data , known as train data , in order to make predict or decis without be explicitli program to do so .',\n",
       " '[ 2 ] machin learn algorithm are use in a wide varieti of applic , such as in medicin , email filter , speech recognit , agricultur , and comput vision , where it is difficult or unfeas to develop convent algorithm to perform the need task .',\n",
       " '[ 3 ] [ 4 ] a subset of machin learn is close relat to comput statist , which focus on make predict use comput , but not all machin learn is statist learn .',\n",
       " 'the studi of mathemat optim deliv method , theori and applic domain to the field of machin learn .',\n",
       " 'data mine is a relat field of studi , focus on exploratori data analysi through unsupervis learn .',\n",
       " '[ 6 ] [ 7 ] some implement of machin learn use data and neural network in a way that mimic the work of a biolog brain .',\n",
       " '[ 8 ] [ 9 ] in it applic across busi problem , machin learn is also refer to as predict analyt .']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0cd72c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine', 'learning', '(', 'ML', ')', 'is', 'a', 'field', 'of', 'inquiry', 'devoted', 'to', 'understanding', 'and', 'building', 'method', 'that', \"'learn\", \"'\", ',', 'that', 'is', ',', 'method', 'that', 'leverage', 'data', 'to', 'improve', 'performance', 'on', 'some', 'set', 'of', 'task', '.']\n",
      "['[', '1', ']', 'It', 'is', 'seen', 'a', 'a', 'part', 'of', 'artificial', 'intelligence', '.']\n",
      "['Machine', 'learning', 'algorithm', 'build', 'a', 'model', 'based', 'on', 'sample', 'data', ',', 'known', 'a', 'training', 'data', ',', 'in', 'order', 'to', 'make', 'prediction', 'or', 'decision', 'without', 'being', 'explicitly', 'programmed', 'to', 'do', 'so', '.']\n",
      "['[', '2', ']', 'Machine', 'learning', 'algorithm', 'are', 'used', 'in', 'a', 'wide', 'variety', 'of', 'application', ',', 'such', 'a', 'in', 'medicine', ',', 'email', 'filtering', ',', 'speech', 'recognition', ',', 'agriculture', ',', 'and', 'computer', 'vision', ',', 'where', 'it', 'is', 'difficult', 'or', 'unfeasible', 'to', 'develop', 'conventional', 'algorithm', 'to', 'perform', 'the', 'needed', 'task', '.']\n",
      "['[', '3', ']', '[', '4', ']', 'A', 'subset', 'of', 'machine', 'learning', 'is', 'closely', 'related', 'to', 'computational', 'statistic', ',', 'which', 'focus', 'on', 'making', 'prediction', 'using', 'computer', ',', 'but', 'not', 'all', 'machine', 'learning', 'is', 'statistical', 'learning', '.']\n",
      "['The', 'study', 'of', 'mathematical', 'optimization', 'delivers', 'method', ',', 'theory', 'and', 'application', 'domain', 'to', 'the', 'field', 'of', 'machine', 'learning', '.']\n",
      "['Data', 'mining', 'is', 'a', 'related', 'field', 'of', 'study', ',', 'focusing', 'on', 'exploratory', 'data', 'analysis', 'through', 'unsupervised', 'learning', '.']\n",
      "['[', '6', ']', '[', '7', ']', 'Some', 'implementation', 'of', 'machine', 'learning', 'use', 'data', 'and', 'neural', 'network', 'in', 'a', 'way', 'that', 'mimic', 'the', 'working', 'of', 'a', 'biological', 'brain', '.']\n",
      "['[', '8', ']', '[', '9', ']', 'In', 'it', 'application', 'across', 'business', 'problem', ',', 'machine', 'learning', 'is', 'also', 'referred', 'to', 'a', 'predictive', 'analytics', '.']\n"
     ]
    }
   ],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[lemmatizer.lemmatize(word) for word in words]\n",
    "    print(words)\n",
    "    corpus.append(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9430490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b05a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "391d680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change\n",
      "change\n",
      "changing\n",
      "changer\n",
      "changeable\n"
     ]
    }
   ],
   "source": [
    "for i in ['changes','change','changing','changer','changeable']:\n",
    "    print(lemmatizer.lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e6e9cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sweet'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('sweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f0e706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better:  good\n"
     ]
    }
   ],
   "source": [
    "print('better: ',lemmatizer.lemmatize('better',pos='a') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "927bb46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ha'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('has')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55f5df0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wa'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('was')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b70d8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Machine learning ( ML ) is a field of inquiry devoted to understanding and building method that 'learn ' , that is , method that leverage data to improve performance on some set of task .\",\n",
       " '[ 1 ] It is seen a a part of artificial intelligence .',\n",
       " 'Machine learning algorithm build a model based on sample data , known a training data , in order to make prediction or decision without being explicitly programmed to do so .',\n",
       " '[ 2 ] Machine learning algorithm are used in a wide variety of application , such a in medicine , email filtering , speech recognition , agriculture , and computer vision , where it is difficult or unfeasible to develop conventional algorithm to perform the needed task .',\n",
       " '[ 3 ] [ 4 ] A subset of machine learning is closely related to computational statistic , which focus on making prediction using computer , but not all machine learning is statistical learning .',\n",
       " 'The study of mathematical optimization delivers method , theory and application domain to the field of machine learning .',\n",
       " 'Data mining is a related field of study , focusing on exploratory data analysis through unsupervised learning .',\n",
       " '[ 6 ] [ 7 ] Some implementation of machine learning use data and neural network in a way that mimic the working of a biological brain .',\n",
       " '[ 8 ] [ 9 ] In it application across business problem , machine learning is also referred to a predictive analytics .']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04bb5c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machin', 'learn', '(', 'ml', ')', 'field', 'inquiri', 'devot', 'understand', 'build', 'method', \"'learn\", \"'\", ',', ',', 'method', 'leverag', 'data', 'improv', 'perform', 'set', 'task', '.']\n",
      "['[', '1', ']', 'seen', 'part', 'artifici', 'intellig', '.']\n",
      "['machin', 'learn', 'algorithm', 'build', 'model', 'base', 'sampl', 'data', ',', 'known', 'train', 'data', ',', 'order', 'make', 'predict', 'decis', 'without', 'explicitli', 'program', '.']\n",
      "['[', '2', ']', 'machin', 'learn', 'algorithm', 'use', 'wide', 'varieti', 'applic', ',', 'medicin', ',', 'email', 'filter', ',', 'speech', 'recognit', ',', 'agricultur', ',', 'comput', 'vision', ',', 'difficult', 'unfeas', 'develop', 'convent', 'algorithm', 'perform', 'need', 'task', '.']\n",
      "['[', '3', ']', '[', '4', ']', 'subset', 'machin', 'learn', 'close', 'relat', 'comput', 'statist', ',', 'focus', 'make', 'predict', 'use', 'comput', ',', 'machin', 'learn', 'statist', 'learn', '.']\n",
      "['studi', 'mathemat', 'optim', 'deliv', 'method', ',', 'theori', 'applic', 'domain', 'field', 'machin', 'learn', '.']\n",
      "['data', 'mine', 'relat', 'field', 'studi', ',', 'focus', 'exploratori', 'data', 'analysi', 'unsupervis', 'learn', '.']\n",
      "['[', '6', ']', '[', '7', ']', 'implement', 'machin', 'learn', 'use', 'data', 'neural', 'network', 'way', 'mimic', 'work', 'biolog', 'brain', '.']\n",
      "['[', '8', ']', '[', '9', ']', 'applic', 'across', 'busi', 'problem', ',', 'machin', 'learn', 'also', 'refer', 'predict', 'analyt', '.']\n"
     ]
    }
   ],
   "source": [
    "#remove stopwords from corpus\n",
    "corpus=[]\n",
    "for i in range(len(sentences)): \n",
    "    words=nltk.word_tokenize(sentences[i].lower())\n",
    "    words=[stemmer.stem(word) for word in words if not word in stop_words]\n",
    "    print(words)\n",
    "    corpus.append(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09a205ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8030fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Machine learning (ML) is a field of inquiry devoted to understanding and building methods that 'learn', that is, methods that leverage data to improve performance on some set of tasks.\",\n",
       " '[1] It is seen as a part of artificial intelligence.',\n",
       " 'Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so.',\n",
       " '[2] Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, agriculture, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.',\n",
       " '[3][4] A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers, but not all machine learning is statistical learning.',\n",
       " 'The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning.',\n",
       " 'Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.',\n",
       " '[6][7] Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.',\n",
       " '[8][9] In its application across business problems, machine learning is also referred to as predictive analytics.']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ff109ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machin', 'learn', '(ml)', 'field', 'inquiri', 'devot', 'understand', 'build', 'method', \"'learn',\", 'is,', 'method', 'leverag', 'data', 'improv', 'perform', 'set', 'tasks.']\n",
      "['[1]', 'seen', 'part', 'artifici', 'intelligence.']\n",
      "['machin', 'learn', 'algorithm', 'build', 'model', 'base', 'sampl', 'data,', 'known', 'train', 'data,', 'order', 'make', 'predict', 'decis', 'without', 'explicitli', 'program', 'so.']\n",
      "['[2]', 'machin', 'learn', 'algorithm', 'use', 'wide', 'varieti', 'applications,', 'medicine,', 'email', 'filtering,', 'speech', 'recognition,', 'agriculture,', 'comput', 'vision,', 'difficult', 'unfeas', 'develop', 'convent', 'algorithm', 'perform', 'need', 'tasks.']\n",
      "['[3][4]', 'subset', 'machin', 'learn', 'close', 'relat', 'comput', 'statistics,', 'focus', 'make', 'predict', 'use', 'computers,', 'machin', 'learn', 'statist', 'learning.']\n",
      "['studi', 'mathemat', 'optim', 'deliv', 'methods,', 'theori', 'applic', 'domain', 'field', 'machin', 'learning.']\n",
      "['data', 'mine', 'relat', 'field', 'study,', 'focus', 'exploratori', 'data', 'analysi', 'unsupervis', 'learning.']\n",
      "['[6][7]', 'implement', 'machin', 'learn', 'use', 'data', 'neural', 'network', 'way', 'mimic', 'work', 'biolog', 'brain.']\n",
      "['[8][9]', 'applic', 'across', 'busi', 'problems,', 'machin', 'learn', 'also', 'refer', 'predict', 'analytics.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "corpus=[]\n",
    "for i in range(len(sentences)): \n",
    "    #remove everything other than a-z and A-Z and replace with a blank\n",
    "    text=re.sub('^a-zA-Z0-9',' ',sentences[i])\n",
    "    text=text.lower()\n",
    "    words= text.split()\n",
    "    words=[stemmer.stem(word) for word in words if not word in stop_words]\n",
    "    print(words)\n",
    "    corpus.append(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5920981a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"machin learn (ml) field inquiri devot understand build method 'learn', is, method leverag data improv perform set tasks.\",\n",
       " '[1] seen part artifici intelligence.',\n",
       " 'machin learn algorithm build model base sampl data, known train data, order make predict decis without explicitli program so.',\n",
       " '[2] machin learn algorithm use wide varieti applications, medicine, email filtering, speech recognition, agriculture, comput vision, difficult unfeas develop convent algorithm perform need tasks.',\n",
       " '[3][4] subset machin learn close relat comput statistics, focus make predict use computers, machin learn statist learning.',\n",
       " 'studi mathemat optim deliv methods, theori applic domain field machin learning.',\n",
       " 'data mine relat field study, focus exploratori data analysi unsupervis learning.',\n",
       " '[6][7] implement machin learn use data neural network way mimic work biolog brain.',\n",
       " '[8][9] applic across busi problems, machin learn also refer predict analytics.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "daf90a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "769fde73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2357ecb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 193)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bagofwords\n",
    "cv.fit_transform(corpus).toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a82736d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##new test data\n",
    "#data=[\"I want to have food\"]\n",
    "data=[\"machine learning is supervised learning\"]\n",
    "cv.transform(data).toarray()\n",
    "#outofvoca probelam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18170414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'machin': 95,\n",
       " 'learn': 84,\n",
       " 'ml': 113,\n",
       " 'field': 64,\n",
       " 'inquiri': 77,\n",
       " 'devot': 52,\n",
       " 'understand': 171,\n",
       " 'build': 25,\n",
       " 'method': 104,\n",
       " 'is': 80,\n",
       " 'leverag': 93,\n",
       " 'data': 39,\n",
       " 'improv': 75,\n",
       " 'perform': 129,\n",
       " 'set': 151,\n",
       " 'tasks': 166,\n",
       " 'machin learn': 96,\n",
       " 'learn ml': 89,\n",
       " 'ml field': 114,\n",
       " 'field inquiri': 65,\n",
       " 'inquiri devot': 78,\n",
       " 'devot understand': 53,\n",
       " 'understand build': 172,\n",
       " 'build method': 26,\n",
       " 'method learn': 105,\n",
       " 'learn is': 88,\n",
       " 'is method': 81,\n",
       " 'method leverag': 106,\n",
       " 'leverag data': 94,\n",
       " 'data improv': 41,\n",
       " 'improv perform': 76,\n",
       " 'perform set': 131,\n",
       " 'set tasks': 152,\n",
       " 'seen': 149,\n",
       " 'part': 127,\n",
       " 'artifici': 18,\n",
       " 'intelligence': 79,\n",
       " 'seen part': 150,\n",
       " 'part artifici': 128,\n",
       " 'artifici intelligence': 19,\n",
       " 'algorithm': 4,\n",
       " 'model': 115,\n",
       " 'base': 20,\n",
       " 'sampl': 147,\n",
       " 'known': 82,\n",
       " 'train': 169,\n",
       " 'order': 125,\n",
       " 'make': 98,\n",
       " 'predict': 132,\n",
       " 'decis': 46,\n",
       " 'without': 189,\n",
       " 'explicitli': 60,\n",
       " 'program': 138,\n",
       " 'so': 153,\n",
       " 'learn algorithm': 85,\n",
       " 'algorithm build': 5,\n",
       " 'build model': 27,\n",
       " 'model base': 116,\n",
       " 'base sampl': 21,\n",
       " 'sampl data': 148,\n",
       " 'data known': 42,\n",
       " 'known train': 83,\n",
       " 'train data': 170,\n",
       " 'data order': 45,\n",
       " 'order make': 126,\n",
       " 'make predict': 99,\n",
       " 'predict decis': 134,\n",
       " 'decis without': 47,\n",
       " 'without explicitli': 190,\n",
       " 'explicitli program': 61,\n",
       " 'program so': 139,\n",
       " 'use': 177,\n",
       " 'wide': 187,\n",
       " 'varieti': 181,\n",
       " 'applications': 16,\n",
       " 'medicine': 102,\n",
       " 'email': 58,\n",
       " 'filtering': 68,\n",
       " 'speech': 154,\n",
       " 'recognition': 140,\n",
       " 'agriculture': 2,\n",
       " 'comput': 32,\n",
       " 'vision': 183,\n",
       " 'difficult': 54,\n",
       " 'unfeas': 173,\n",
       " 'develop': 50,\n",
       " 'convent': 37,\n",
       " 'need': 117,\n",
       " 'algorithm use': 7,\n",
       " 'use wide': 180,\n",
       " 'wide varieti': 188,\n",
       " 'varieti applications': 182,\n",
       " 'applications medicine': 17,\n",
       " 'medicine email': 103,\n",
       " 'email filtering': 59,\n",
       " 'filtering speech': 69,\n",
       " 'speech recognition': 155,\n",
       " 'recognition agriculture': 141,\n",
       " 'agriculture comput': 3,\n",
       " 'comput vision': 34,\n",
       " 'vision difficult': 184,\n",
       " 'difficult unfeas': 55,\n",
       " 'unfeas develop': 174,\n",
       " 'develop convent': 51,\n",
       " 'convent algorithm': 38,\n",
       " 'algorithm perform': 6,\n",
       " 'perform need': 130,\n",
       " 'need tasks': 118,\n",
       " 'subset': 164,\n",
       " 'close': 30,\n",
       " 'relat': 144,\n",
       " 'statistics': 158,\n",
       " 'focus': 70,\n",
       " 'computers': 35,\n",
       " 'statist': 156,\n",
       " 'learning': 92,\n",
       " 'subset machin': 165,\n",
       " 'learn close': 87,\n",
       " 'close relat': 31,\n",
       " 'relat comput': 145,\n",
       " 'comput statistics': 33,\n",
       " 'statistics focus': 159,\n",
       " 'focus make': 72,\n",
       " 'predict use': 135,\n",
       " 'use computers': 178,\n",
       " 'computers machin': 36,\n",
       " 'learn statist': 90,\n",
       " 'statist learning': 157,\n",
       " 'studi': 160,\n",
       " 'mathemat': 100,\n",
       " 'optim': 123,\n",
       " 'deliv': 48,\n",
       " 'methods': 107,\n",
       " 'theori': 167,\n",
       " 'applic': 13,\n",
       " 'domain': 56,\n",
       " 'studi mathemat': 161,\n",
       " 'mathemat optim': 101,\n",
       " 'optim deliv': 124,\n",
       " 'deliv methods': 49,\n",
       " 'methods theori': 108,\n",
       " 'theori applic': 168,\n",
       " 'applic domain': 15,\n",
       " 'domain field': 57,\n",
       " 'field machin': 66,\n",
       " 'machin learning': 97,\n",
       " 'mine': 111,\n",
       " 'study': 162,\n",
       " 'exploratori': 62,\n",
       " 'analysi': 10,\n",
       " 'unsupervis': 175,\n",
       " 'data mine': 43,\n",
       " 'mine relat': 112,\n",
       " 'relat field': 146,\n",
       " 'field study': 67,\n",
       " 'study focus': 163,\n",
       " 'focus exploratori': 71,\n",
       " 'exploratori data': 63,\n",
       " 'data analysi': 40,\n",
       " 'analysi unsupervis': 11,\n",
       " 'unsupervis learning': 176,\n",
       " 'implement': 73,\n",
       " 'neural': 121,\n",
       " 'network': 119,\n",
       " 'way': 185,\n",
       " 'mimic': 109,\n",
       " 'work': 191,\n",
       " 'biolog': 22,\n",
       " 'brain': 24,\n",
       " 'implement machin': 74,\n",
       " 'learn use': 91,\n",
       " 'use data': 179,\n",
       " 'data neural': 44,\n",
       " 'neural network': 122,\n",
       " 'network way': 120,\n",
       " 'way mimic': 186,\n",
       " 'mimic work': 110,\n",
       " 'work biolog': 192,\n",
       " 'biolog brain': 23,\n",
       " 'across': 0,\n",
       " 'busi': 28,\n",
       " 'problems': 136,\n",
       " 'also': 8,\n",
       " 'refer': 142,\n",
       " 'analytics': 12,\n",
       " 'applic across': 14,\n",
       " 'across busi': 1,\n",
       " 'busi problems': 29,\n",
       " 'problems machin': 137,\n",
       " 'learn also': 86,\n",
       " 'also refer': 9,\n",
       " 'refer predict': 143,\n",
       " 'predict analytics': 133}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a649737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1bfe5f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf= TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ad53b70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.20855424, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1602166 , 0.        ,\n",
       "        0.        , 0.        , 0.24692198, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18133189, 0.        ,\n",
       "        0.        , 0.        , 0.24692198, 0.24692198, 0.        ,\n",
       "        0.24692198, 0.        , 0.25675481, 0.        , 0.24692198,\n",
       "        0.1157418 , 0.        , 0.        , 0.        , 0.49384396,\n",
       "        0.        , 0.        , 0.        , 0.24692198, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20855424, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24692198, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20855424, 0.        ,\n",
       "        0.        , 0.24692198, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5       , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.21212735, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.25115244,\n",
       "        0.        , 0.        , 0.21212735, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3259231 , 0.25115244,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25115244, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25115244, 0.13057687, 0.        , 0.        ,\n",
       "        0.11772478, 0.21212735, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.25115244,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.25115244,\n",
       "        0.        , 0.        , 0.18443861, 0.        , 0.25115244,\n",
       "        0.        , 0.        , 0.        , 0.25115244, 0.        ,\n",
       "        0.        , 0.25115244, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.25115244, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.25115244,\n",
       "        0.        ],\n",
       "       [0.        , 0.21809873, 0.36841932, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.21809873, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.18420966, 0.        , 0.21809873, 0.        , 0.        ,\n",
       "        0.        , 0.21809873, 0.        , 0.21809873, 0.        ,\n",
       "        0.21809873, 0.        , 0.        , 0.        , 0.21809873,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.11339188, 0.        , 0.        ,\n",
       "        0.10223123, 0.        , 0.        , 0.21809873, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.21809873, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.18420966, 0.        , 0.        , 0.        ,\n",
       "        0.21809873, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.21809873, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18420966, 0.        ,\n",
       "        0.        , 0.        , 0.21809873, 0.        , 0.16016498,\n",
       "        0.21809873, 0.21809873, 0.        , 0.21809873, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29576623,\n",
       "        0.24980887, 0.29576623, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24980887, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30754411, 0.2172016 , 0.        ,\n",
       "        0.27727393, 0.24980887, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2172016 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.24980887, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.29576623, 0.29576623,\n",
       "        0.        , 0.        , 0.29576623, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.2172016 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.28135601, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3331171 , 0.        , 0.        , 0.        , 0.3331171 ,\n",
       "        0.        , 0.        , 0.        , 0.24463093, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24463093, 0.        ,\n",
       "        0.15614475, 0.        , 0.3331171 , 0.        , 0.        ,\n",
       "        0.3331171 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3331171 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3331171 , 0.        , 0.        , 0.        , 0.3331171 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.32988033,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.42808909, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32988033, 0.24225394, 0.        ,\n",
       "        0.27862218, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24225394, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32988033, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.27862218, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32988033, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.32988033, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.32529428, 0.32529428, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.21106886, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32529428, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16912401, 0.        , 0.        ,\n",
       "        0.15247789, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32529428, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.32529428, 0.32529428, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.23888609,\n",
       "        0.        , 0.        , 0.32529428, 0.        , 0.        ,\n",
       "        0.32529428],\n",
       "       [0.35937997, 0.        , 0.        , 0.35937997, 0.        ,\n",
       "        0.35937997, 0.30353804, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.35937997, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.18684553, 0.        , 0.        ,\n",
       "        0.16845516, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.26391757, 0.35937997, 0.        ,\n",
       "        0.        , 0.35937997, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "00d0aa09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'machin': 40,\n",
       " 'learn': 37,\n",
       " 'ml': 48,\n",
       " 'field': 28,\n",
       " 'inquiri': 33,\n",
       " 'devot': 22,\n",
       " 'understand': 76,\n",
       " 'build': 12,\n",
       " 'method': 44,\n",
       " 'is': 35,\n",
       " 'leverag': 39,\n",
       " 'data': 18,\n",
       " 'improv': 32,\n",
       " 'perform': 56,\n",
       " 'set': 65,\n",
       " 'tasks': 73,\n",
       " 'seen': 64,\n",
       " 'part': 55,\n",
       " 'artifici': 8,\n",
       " 'intelligence': 34,\n",
       " 'algorithm': 2,\n",
       " 'model': 49,\n",
       " 'base': 9,\n",
       " 'sampl': 63,\n",
       " 'known': 36,\n",
       " 'train': 75,\n",
       " 'order': 54,\n",
       " 'make': 41,\n",
       " 'predict': 57,\n",
       " 'decis': 19,\n",
       " 'without': 84,\n",
       " 'explicitli': 26,\n",
       " 'program': 59,\n",
       " 'so': 66,\n",
       " 'use': 79,\n",
       " 'wide': 83,\n",
       " 'varieti': 80,\n",
       " 'applications': 7,\n",
       " 'medicine': 43,\n",
       " 'email': 25,\n",
       " 'filtering': 29,\n",
       " 'speech': 67,\n",
       " 'recognition': 60,\n",
       " 'agriculture': 1,\n",
       " 'comput': 15,\n",
       " 'vision': 81,\n",
       " 'difficult': 23,\n",
       " 'unfeas': 77,\n",
       " 'develop': 21,\n",
       " 'convent': 17,\n",
       " 'need': 50,\n",
       " 'subset': 72,\n",
       " 'close': 14,\n",
       " 'relat': 62,\n",
       " 'statistics': 69,\n",
       " 'focus': 30,\n",
       " 'computers': 16,\n",
       " 'statist': 68,\n",
       " 'learning': 38,\n",
       " 'studi': 70,\n",
       " 'mathemat': 42,\n",
       " 'optim': 53,\n",
       " 'deliv': 20,\n",
       " 'methods': 45,\n",
       " 'theori': 74,\n",
       " 'applic': 6,\n",
       " 'domain': 24,\n",
       " 'mine': 47,\n",
       " 'study': 71,\n",
       " 'exploratori': 27,\n",
       " 'analysi': 4,\n",
       " 'unsupervis': 78,\n",
       " 'implement': 31,\n",
       " 'neural': 52,\n",
       " 'network': 51,\n",
       " 'way': 82,\n",
       " 'mimic': 46,\n",
       " 'work': 85,\n",
       " 'biolog': 10,\n",
       " 'brain': 11,\n",
       " 'across': 0,\n",
       " 'busi': 13,\n",
       " 'problems': 58,\n",
       " 'also': 3,\n",
       " 'refer': 61,\n",
       " 'analytics': 5}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254000b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
